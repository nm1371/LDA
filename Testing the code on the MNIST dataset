import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, random_split
from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim
import numpy as np
import matplotlib.pyplot as plt

# âš™ï¸ ØªØ§Ø¨Ø¹ ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù‚Ø·Ø¹Ù‡â€ŒØ§ÛŒ
class PiecewiseActivation(nn.Module):
    def __init__(self, delta=0.01):
        super().__init__()
        self.delta = delta

    def forward(self, x):
        out = torch.zeros_like(x)
        out[x <= -self.delta] = 0
        mid = (x > -self.delta) & (x <= self.delta)
        out[mid] = 0.5 * x[mid]**2 + 0.5 * self.delta**2
        out[x > self.delta] = x[x > self.delta]
        return out

# ğŸ§  Ø´Ø¨Ú©Ù‡ G Ø¨Ø§ BatchNorm Ùˆ ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØ´ØªØ±
class GNetwork(nn.Module):
    def __init__(self):
        super().__init__()
        self.activation = PiecewiseActivation()
        self.conv1 = nn.Conv2d(1, 32, 3, padding=1, bias=False)
        self.bn1 = nn.BatchNorm2d(32)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1, bias=False)
        self.bn2 = nn.BatchNorm2d(64)
        self.conv3 = nn.Conv2d(64, 64, 3, padding=1, bias=False)
        self.bn3 = nn.BatchNorm2d(64)
        self.conv4 = nn.Conv2d(64, 32, 3, padding=1, bias=False)
        self.bn4 = nn.BatchNorm2d(32)
        self.conv_out = nn.Conv2d(32, 1, 3, padding=1)

    def forward(self, x):
        x = self.activation(self.bn1(self.conv1(x)))
        x = self.activation(self.bn2(self.conv2(x)))
        x = self.activation(self.bn3(self.conv3(x)))
        x = self.activation(self.bn4(self.conv4(x)))
        return self.conv_out(x)

# ğŸ” ØªØ§Ø¨Ø¹ r_epsilon Ùˆ Ø§Ù„Ú¯ÙˆØ±ÛŒØªÙ… LDA Ø¨Ø§ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¬Ø¯ÛŒØ¯
def r_epsilon(x, g_net, epsilon=1e-2):
    g = g_net(x)
    norm = torch.norm(g, dim=1, keepdim=True)
    reg = torch.where(norm <= epsilon, 0.5 / epsilon * norm**2, norm - epsilon / 2)
    return reg.sum()

def LDA(x0, y, g_net, alpha=0.05, tau=0.05, gamma=0.9,
        epsilon0=1.0, sigma=0.01, epsilon_tol=1e-6, max_iter=15):

    x = x0.clone().requires_grad_()
    epsilon = epsilon0

    for _ in range(max_iter):
        grad_f = 2 * (x - y)
        z = x - alpha * grad_f
        z = z.requires_grad_()

        ru = r_epsilon(z, g_net, epsilon)
        grad_ru = torch.autograd.grad(ru, z, create_graph=True)[0]

        x = x.requires_grad_()
        rv = r_epsilon(x, g_net, epsilon)
        grad_rv = torch.autograd.grad(rv, x, create_graph=True)[0]

        u = z - tau * grad_ru
        v = z - alpha * grad_rv

        ru_val = r_epsilon(u.requires_grad_(), g_net, epsilon)
        rv_val = r_epsilon(v.requires_grad_(), g_net, epsilon)

        x_next = u if ru_val <= rv_val else v
        grad_total = 2 * (x_next - y)

        if torch.norm(grad_total) < sigma * gamma * epsilon:
            epsilon *= gamma
        if sigma * epsilon < epsilon_tol:
            break

        x = x_next.clone().requires_grad_()

    return x

# ğŸ“¥ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
transform = transforms.ToTensor()
dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
train_set, test_set = random_split(dataset, [50000, 10000])
train_loader = DataLoader(train_set, batch_size=1, shuffle=True)
test_loader = DataLoader(test_set, batch_size=1, shuffle=False)

# ğŸ‹ï¸ Ø¢Ù…ÙˆØ²Ø´ G Ø¨Ø§ Ø¯Ø§Ø¯Ù‡ Ø§ØµÙ„ÛŒ
g_net = GNetwork()
optimizer = optim.Adam(g_net.parameters(), lr=1e-3)
loss_fn = nn.MSELoss()

for i, (img, _) in enumerate(train_loader):
    if i >= 1000: break
    noisy = img + 0.1 * torch.randn_like(img)
    clean = img
    optimizer.zero_grad()
    output = LDA(noisy, clean, g_net)
    loss = loss_fn(output, clean)
    loss.backward()
    optimizer.step()

# ğŸ¯ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ø±ÙˆÛŒ ØªØ³Øª
psnr_vals, ssim_vals = [], []

for i, (img, _) in enumerate(test_loader):
    if i >= 5: break
    noisy = img + 0.1 * torch.randn_like(img)
    result = LDA(noisy, img, g_net)

    original_np = img.squeeze().numpy()
    result_np = result.squeeze().detach().numpy()

    psnr_vals.append(psnr(original_np, result_np))
    ssim_vals.append(ssim(original_np, result_np, data_range=1.0))

    plt.figure(figsize=(12, 4))
    plt.subplot(1, 3, 1); plt.title("Original"); plt.imshow(original_np, cmap='gray'); plt.axis('off')
    plt.subplot(1, 3, 2); plt.title("Noisy"); plt.imshow(noisy.squeeze().numpy(), cmap='gray'); plt.axis('off')
    plt.subplot(1, 3, 3); plt.title("Denoised"); plt.imshow(result_np, cmap='gray'); plt.axis('off')
    plt.tight_layout(); plt.show()

print("ğŸ”¸ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† PSNR:", np.mean(psnr_vals))
print("ğŸ”¹ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† SSIM:", np.mean(ssim_vals))
